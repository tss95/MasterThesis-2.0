{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "\n",
    "base_dir = 'C:\\Documents\\Thesis_ssd\\MasterThesis-2.0'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.BaselineHelperFunctions import BaselineHelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.DataGenerator import DataGenerator\n",
    "from Classes.Modeling.Models import Models\n",
    "from Classes.Modeling.RandomGridSearch import RandomGridSearch\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "import json\n",
    "\n",
    "helper = BaselineHelperFunctions()\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "loadData = LoadData(num_classes = 2, isBalanced = True)\n",
    "shuffle = False\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.getDatasets(shuffle = shuffle)\n",
    "handler = DataHandler()\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "helper = BaselineHelperFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid = {\n",
    "        \"batch_size\" : [8, 16, 32, 64, 128, 256],\n",
    "        \"epochs\" : [30, 35, 40],\n",
    "        \"learning_rate\" : [0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "        \"optimizer\" : [\"adam\", \"rmsprop\", \"sgd\"]\n",
    "    }\n",
    "model_grid = {\n",
    "    \"start_neurons\" : [4,8,16, 32, 64, 128, 256, 512],\n",
    "    \"dropout_rate\" : [0.5, 0.4, 0.3, 0.2, 0.1, 0.01, 0],\n",
    "    \"filters\" : [11, 13, 15, 17, 19, 21, 23, 25],\n",
    "    \"kernel_size\" : [3, 5, 7, 9, 11, 13],\n",
    "    \"padding\" : [\"same\"],\n",
    "    \"l2_r\" : [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"l1_r\" : [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"activation\" : [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"],\n",
    "    \"output_layer_activation\" : [\"softmax\", \"sigmoid\"]\n",
    "}\n",
    "\n",
    "\n",
    "model_nr = 4\n",
    "test_mode = False\n",
    "use_scaler = True\n",
    "use_noise_augmentor = True\n",
    "detrend = False\n",
    "use_minmax = False\n",
    "n_picks = 40\n",
    "use_tensorboard = False\n",
    "\n",
    "randomGridSearch = RandomGridSearch(train_ds, val_ds, test_ds, model_nr, test_mode, detrend,\n",
    "                                    use_scaler, use_noise_augmentor, use_minmax, n_picks, \n",
    "                                    hyper_grid = hyper_grid, model_grid = model_grid, \n",
    "                                    num_classes = num_classes, use_tensorboard = use_tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = f\"{base_dir}/Tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "if use_tensorboard:\n",
    "    clear_tensorboard_dir()\n",
    "    %tensorboard --logdir tensorboard_dir/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (32, 128)                 3138560   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (32, 128)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (32, 128)                 512       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 2)                   258       \n",
      "=================================================================\n",
      "Total params: 3,139,330\n",
      "Trainable params: 3,139,074\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 32, 'epochs': 35, 'learning_rate': 0.1, 'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'sigmoid',\n",
      "    'dropout_rate': 0.1,\n",
      "    'filters': 25,\n",
      "    'kernel_size': 5,\n",
      "    'l1_r': 0.3,\n",
      "    'l2_r': 0.1,\n",
      "    'output_layer_activation': 'sigmoid',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 128}\n",
      "Epoch 1/35\n",
      "263/342 [======================>.......] - ETA: 8s - loss: 14040.9727 - accuracy: 0.4989 - precision: 0.4983 - recall: 0.4961"
     ]
    }
   ],
   "source": [
    "results, highest_test_accuracy_index, highest_train_accuracy_index, highest_test_precision_index, highest_test_recall_index= randomGridSearch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = randomGridSearch.read_results()\n",
    "print(dictionaries)\n",
    "use_tensorboard = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest test accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_accuracy = randomGridSearch.fit_from_result(dictionaries, highest_test_accuracy_index, use_tensorboard = use_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest train accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_accuracy = randomGridSearch.fit_from_result(dictionaries, highest_train_accuracy_index, use_tensorboard = use_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_precision = randomGridSearch.fit_from_result(dictionaries, highest_test_precision_index, use_tensorboard = use_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_recall = randomGridSearch.fit_from_result(dictionaries, highest_test_recall_index, use_tensorboard = use_tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
