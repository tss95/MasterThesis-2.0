{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import Stream, Trace, UTCDateTime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Flatten, MaxPooling3D, BatchNormalization, InputLayer, LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import sys\n",
    "classes_dir = 'C:\\Documents\\Thesis_ssd\\MasterThesis-2.0'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.BaselineHelperFunctions import BaselineHelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.DataGenerator import DataGenerator\n",
    "from Classes.DataProcessing.NoiseAugmentor import NoiseAugmentor\n",
    "from Classes.Modeling.Models import Models\n",
    "from Classes.Modeling.RandomGridSearch import RandomGridSearch\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "from Classes import Tf_shutup\n",
    "Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = BaselineHelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "base_dir = 'C:\\Documents\\Thesis_ssd\\MasterThesis-2.0'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "loadData = LoadData(num_classes = num_classes, isBalanced = True)\n",
    "shuffle = True\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.getDatasets(shuffle = shuffle)\n",
    "data_gen = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'model_nr': 5, 'index': 10}\n",
    "{'batch_size': 32, 'epochs': 35, 'learning_rate': 1e-05, 'optimizer': 'rmsprop'}\n",
    "{'activation': 'relu', 'dropout_rate': 0.4, 'filters': 21, 'kernel_size': 7, 'l1_r': 0.001, 'l2_r': 0.2, \n",
    "'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 16}\n",
    "\n",
    "{'model_nr': 4, 'index': 10}\n",
    "{'batch_size': 8, 'epochs': 30, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
    "{'activation': 'relu', 'dropout_rate': 0.3, 'filters': 17, 'kernel_size': 3, 'l1_r': 0.01, 'l2_r': 0.1, \n",
    "'output_layer_activation': 'softmax', 'padding': 'same', 'start_neurons': 128}\n",
    "\n",
    "Crashing model:\n",
    "Test_mode: False, use_scaler: True, use_minmax: False, use_noise_augmentor: True, detrend: False\n",
    "{'model_nr': 4, 'index': 21}\n",
    "{'batch_size': 16, 'epochs': 35, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
    "{'activation': 'relu', 'dropout_rate': 0.01, 'filters': 15, 'kernel_size': 13, 'l1_r': 0.0001, \n",
    "'l2_r': 0.2, 'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 64}\n",
    "\n",
    "{'model_nr': 7, 'index': 38}\n",
    "Test_mode: False, use_scaler: True, use_minmax: False, use_noise_augmentor: True detrend: False. \n",
    "{'batch_size': 64, 'epochs': 40, 'learning_rate': 0.001, 'optimizer': 'rmsprop'}\n",
    "{'activation': 'tanh', 'dropout_rate': 0, 'filters': 13, 'kernel_size': 5, 'l1_r': 0.0001,\n",
    "'l2_r': 0.01, 'output_layer_activation': 'softmax', 'padding': 'same', 'start_neurons': 32}\n",
    "{'test_loss': 1.4299607276916504, 'test_accuracy': 0.7728365659713745, \n",
    "'test_precision': 0.7728365659713745, 'test_recall': 0.7728365659713745}\n",
    "{'train_loss': 0.9629267454147339, 'train_accuracy': 0.8897058963775635, \n",
    "'train_precision': 0.8897058963775635, 'train_recall': 0.8897058963775635}\n",
    "\n",
    "\"\"\"\n",
    "############ Model picker #############\n",
    "model_nr = 8\n",
    "\n",
    "########### Hyperparameters ###########\n",
    "batch_size = 64\n",
    "epochs = 80\n",
    "learning_rate = 0.001\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, clipnorm=1.0, clipvalue=0.5)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "activation = 'tanh'\n",
    "output_layer_activation = 'softmax'\n",
    "dropout_rate = 0\n",
    "filters = 13\n",
    "kernel_size = 5\n",
    "l1_r = 0.0001\n",
    "l2_r = 0.01\n",
    "padding = 'same'\n",
    "start_neurons = 32\n",
    "\n",
    "########### Preprocessing ###########\n",
    "test = False\n",
    "use_noise_augmentor = True\n",
    "detrend = False\n",
    "use_scaler = True\n",
    "use_highpass = False\n",
    "highpass_freq = 0.2\n",
    "\n",
    "use_tensorboard = True\n",
    "use_livelossplot = False\n",
    "use_custom = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20201019-150002']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13444), started 3:42:05 ago. (Use '!kill 13444' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e34df3d72b0d88e2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e34df3d72b0d88e2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = f\"{base_dir}/Tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "        \n",
    "if use_tensorboard:\n",
    "    import datetime\n",
    "    clear_tensorboard_dir()\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir tensorboard_dir/fit\n",
    "    log_dir = f\"{base_dir}/tensorboard_dir/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    callbacks = [tensorboard_callback]\n",
    "\n",
    "if use_custom:\n",
    "    custom_callback = CustomCallback(data_gen)\n",
    "    callbacks = custom_callback\n",
    "elif use_livelossplot:\n",
    "    callbacks = PlotLossesKeras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (64, 3, 32)               772352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (64, 3, 32)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (64, 3, 32)               128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, 3, 16)               3136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (64, 3, 16)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (64, 3, 16)               64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, 3, 8)                136       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (64, 3, 8)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (64, 3, 8)                32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (64, 24)                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, 3)                   75        \n",
      "=================================================================\n",
      "Total params: 775,923\n",
      "Trainable params: 775,811\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_ds, channels, timesteps = data_gen.get_trace_shape_no_cast(train_ds)\n",
    "input_shape = (batch_size, channels, timesteps)\n",
    "\n",
    "build_model_args = {'model_nr' : model_nr,\n",
    "                    'input_shape' : input_shape,\n",
    "                    'num_classes' : num_classes,\n",
    "                    'dropout_rate' : dropout_rate,\n",
    "                    'activation' : activation,\n",
    "                    'output_layer_activation' : output_layer_activation,\n",
    "                    'l2_r' : l2_r,\n",
    "                    'l1_r' : l1_r,\n",
    "                    'full_regularizer' : True,\n",
    "                    'start_neurons' : start_neurons,\n",
    "                    'filters' : filters,\n",
    "                    'kernel_size' : kernel_size,\n",
    "                    'padding' : 'same'}\n",
    "model = Models(**build_model_args).model\n",
    "\n",
    "model_args = {'loss' : \"binary_crossentropy\",\n",
    "              'optimizer' : opt,\n",
    "              'metrics' : [\"accuracy\",\"MSE\",\n",
    "                           tf.keras.metrics.Precision(thresholds=None, top_k=None, class_id=None, name=None, dtype=None),\n",
    "                           tf.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)]}\n",
    "model.compile(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "  1/256 [..............................] - ETA: 0s - loss: 5.5937 - accuracy: 0.3750 - MSE: 0.2773 - precision: 0.3261 - recall: 0.2344WARNING:tensorflow:From C:\\Users\\tss_9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/256 [..............................] - ETA: 19s - loss: 5.5122 - accuracy: 0.3438 - MSE: 0.3041 - precision: 0.3137 - recall: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0270s vs `on_train_batch_end` time: 0.1233s). Check your callbacks.\n",
      "257/256 [==============================] - 47s 182ms/step - loss: 2.3036 - accuracy: 0.4260 - MSE: 0.2206 - precision: 0.4897 - recall: 0.1975 - val_loss: 1.5468 - val_accuracy: 0.3837 - val_MSE: 0.2194 - val_precision: 0.7500 - val_recall: 0.0021\n",
      "Epoch 2/80\n",
      "257/256 [==============================] - 44s 169ms/step - loss: 1.3132 - accuracy: 0.5268 - MSE: 0.1911 - precision: 0.6557 - recall: 0.3029 - val_loss: 1.2453 - val_accuracy: 0.4934 - val_MSE: 0.2002 - val_precision: 0.6764 - val_recall: 0.1771\n",
      "Epoch 3/80\n",
      "257/256 [==============================] - 43s 169ms/step - loss: 1.1392 - accuracy: 0.5714 - MSE: 0.1786 - precision: 0.6863 - recall: 0.3718 - val_loss: 1.1255 - val_accuracy: 0.5302 - val_MSE: 0.1898 - val_precision: 0.6732 - val_recall: 0.2861\n",
      "Epoch 4/80\n",
      "257/256 [==============================] - 43s 168ms/step - loss: 1.0564 - accuracy: 0.5962 - MSE: 0.1711 - precision: 0.7073 - recall: 0.4128 - val_loss: 1.1098 - val_accuracy: 0.5483 - val_MSE: 0.1860 - val_precision: 0.6401 - val_recall: 0.3576\n",
      "Epoch 5/80\n",
      "257/256 [==============================] - 43s 167ms/step - loss: 1.0183 - accuracy: 0.6156 - MSE: 0.1642 - precision: 0.7192 - recall: 0.4503 - val_loss: 1.0719 - val_accuracy: 0.5552 - val_MSE: 0.1827 - val_precision: 0.6538 - val_recall: 0.3809\n",
      "Epoch 6/80\n",
      "257/256 [==============================] - 43s 168ms/step - loss: 1.0116 - accuracy: 0.6285 - MSE: 0.1590 - precision: 0.7299 - recall: 0.4801 - val_loss: 1.1168 - val_accuracy: 0.5580 - val_MSE: 0.1835 - val_precision: 0.6509 - val_recall: 0.3955\n",
      "Epoch 7/80\n",
      "257/256 [==============================] - 43s 168ms/step - loss: 1.0170 - accuracy: 0.6463 - MSE: 0.1546 - precision: 0.7377 - recall: 0.5058 - val_loss: 1.1154 - val_accuracy: 0.5646 - val_MSE: 0.1826 - val_precision: 0.6257 - val_recall: 0.4451\n",
      "Epoch 8/80\n",
      "257/256 [==============================] - 43s 169ms/step - loss: 1.0125 - accuracy: 0.6546 - MSE: 0.1499 - precision: 0.7437 - recall: 0.5285 - val_loss: 1.1347 - val_accuracy: 0.5847 - val_MSE: 0.1762 - val_precision: 0.6633 - val_recall: 0.4556\n",
      "Epoch 9/80\n",
      "257/256 [==============================] - 43s 168ms/step - loss: 0.9938 - accuracy: 0.6675 - MSE: 0.1452 - precision: 0.7488 - recall: 0.5508 - val_loss: 1.1383 - val_accuracy: 0.5764 - val_MSE: 0.1816 - val_precision: 0.6409 - val_recall: 0.4642\n",
      "Epoch 10/80\n",
      "257/256 [==============================] - 43s 169ms/step - loss: 0.9915 - accuracy: 0.6771 - MSE: 0.1427 - precision: 0.7535 - recall: 0.5621 - val_loss: 1.1299 - val_accuracy: 0.5663 - val_MSE: 0.1813 - val_precision: 0.6302 - val_recall: 0.4941\n",
      "Epoch 11/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.9762 - accuracy: 0.6873 - MSE: 0.1388 - precision: 0.7585 - recall: 0.5838 - val_loss: 1.1357 - val_accuracy: 0.5774 - val_MSE: 0.1830 - val_precision: 0.6286 - val_recall: 0.4906\n",
      "Epoch 12/80\n",
      "257/256 [==============================] - 44s 169ms/step - loss: 0.9837 - accuracy: 0.6932 - MSE: 0.1359 - precision: 0.7607 - recall: 0.5970 - val_loss: 1.1218 - val_accuracy: 0.5788 - val_MSE: 0.1831 - val_precision: 0.6219 - val_recall: 0.5066\n",
      "Epoch 13/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.9736 - accuracy: 0.7003 - MSE: 0.1334 - precision: 0.7679 - recall: 0.6083 - val_loss: 1.1960 - val_accuracy: 0.5760 - val_MSE: 0.1854 - val_precision: 0.6171 - val_recall: 0.5097\n",
      "Epoch 14/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.9818 - accuracy: 0.7105 - MSE: 0.1292 - precision: 0.7749 - recall: 0.6242 - val_loss: 1.1340 - val_accuracy: 0.5924 - val_MSE: 0.1797 - val_precision: 0.6353 - val_recall: 0.5128\n",
      "Epoch 15/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.9564 - accuracy: 0.7124 - MSE: 0.1280 - precision: 0.7753 - recall: 0.6273 - val_loss: 1.0971 - val_accuracy: 0.6024 - val_MSE: 0.1769 - val_precision: 0.6498 - val_recall: 0.5302\n",
      "Epoch 16/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.9526 - accuracy: 0.7239 - MSE: 0.1258 - precision: 0.7807 - recall: 0.6417 - val_loss: 1.1281 - val_accuracy: 0.5972 - val_MSE: 0.1768 - val_precision: 0.6405 - val_recall: 0.5177\n",
      "Epoch 17/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.9433 - accuracy: 0.7266 - MSE: 0.1223 - precision: 0.7842 - recall: 0.6540 - val_loss: 1.1479 - val_accuracy: 0.5948 - val_MSE: 0.1786 - val_precision: 0.6355 - val_recall: 0.5340\n",
      "Epoch 18/80\n",
      "257/256 [==============================] - 45s 176ms/step - loss: 0.9278 - accuracy: 0.7325 - MSE: 0.1209 - precision: 0.7841 - recall: 0.6573 - val_loss: 1.1114 - val_accuracy: 0.6014 - val_MSE: 0.1771 - val_precision: 0.6456 - val_recall: 0.5250\n",
      "Epoch 19/80\n",
      "257/256 [==============================] - 46s 177ms/step - loss: 0.9192 - accuracy: 0.7384 - MSE: 0.1186 - precision: 0.7893 - recall: 0.6695 - val_loss: 1.1330 - val_accuracy: 0.6056 - val_MSE: 0.1755 - val_precision: 0.6433 - val_recall: 0.5253\n",
      "Epoch 20/80\n",
      "257/256 [==============================] - 46s 177ms/step - loss: 0.9135 - accuracy: 0.7467 - MSE: 0.1158 - precision: 0.7968 - recall: 0.6799 - val_loss: 1.1383 - val_accuracy: 0.6108 - val_MSE: 0.1739 - val_precision: 0.6557 - val_recall: 0.5469\n",
      "Epoch 21/80\n",
      "257/256 [==============================] - 46s 178ms/step - loss: 0.9033 - accuracy: 0.7503 - MSE: 0.1139 - precision: 0.7997 - recall: 0.6866 - val_loss: 1.0883 - val_accuracy: 0.6118 - val_MSE: 0.1727 - val_precision: 0.6520 - val_recall: 0.5569\n",
      "Epoch 22/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.9021 - accuracy: 0.7512 - MSE: 0.1138 - precision: 0.7971 - recall: 0.6887 - val_loss: 1.1428 - val_accuracy: 0.6132 - val_MSE: 0.1736 - val_precision: 0.6511 - val_recall: 0.5604\n",
      "Epoch 23/80\n",
      "257/256 [==============================] - 44s 169ms/step - loss: 0.8993 - accuracy: 0.7573 - MSE: 0.1117 - precision: 0.8025 - recall: 0.6952 - val_loss: 1.1209 - val_accuracy: 0.6083 - val_MSE: 0.1772 - val_precision: 0.6445 - val_recall: 0.5677\n",
      "Epoch 24/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.8889 - accuracy: 0.7592 - MSE: 0.1100 - precision: 0.8030 - recall: 0.7017 - val_loss: 1.1308 - val_accuracy: 0.6160 - val_MSE: 0.1759 - val_precision: 0.6521 - val_recall: 0.5583\n",
      "Epoch 25/80\n",
      "257/256 [==============================] - 44s 169ms/step - loss: 0.8796 - accuracy: 0.7648 - MSE: 0.1082 - precision: 0.8048 - recall: 0.7072 - val_loss: 1.1527 - val_accuracy: 0.6118 - val_MSE: 0.1800 - val_precision: 0.6431 - val_recall: 0.5688\n",
      "Epoch 26/80\n",
      "257/256 [==============================] - 45s 174ms/step - loss: 0.8704 - accuracy: 0.7657 - MSE: 0.1076 - precision: 0.8083 - recall: 0.7130 - val_loss: 1.1148 - val_accuracy: 0.6226 - val_MSE: 0.1739 - val_precision: 0.6596 - val_recall: 0.5611\n",
      "Epoch 27/80\n",
      "257/256 [==============================] - 45s 174ms/step - loss: 0.8702 - accuracy: 0.7712 - MSE: 0.1057 - precision: 0.8129 - recall: 0.7178 - val_loss: 1.0880 - val_accuracy: 0.6201 - val_MSE: 0.1738 - val_precision: 0.6515 - val_recall: 0.5660\n",
      "Epoch 28/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.8548 - accuracy: 0.7700 - MSE: 0.1058 - precision: 0.8096 - recall: 0.7180 - val_loss: 1.1284 - val_accuracy: 0.6160 - val_MSE: 0.1792 - val_precision: 0.6367 - val_recall: 0.5701\n",
      "Epoch 29/80\n",
      "257/256 [==============================] - 45s 173ms/step - loss: 0.8630 - accuracy: 0.7729 - MSE: 0.1042 - precision: 0.8125 - recall: 0.7235 - val_loss: 1.1549 - val_accuracy: 0.6097 - val_MSE: 0.1823 - val_precision: 0.6329 - val_recall: 0.5795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80\n",
      "257/256 [==============================] - 46s 179ms/step - loss: 0.8591 - accuracy: 0.7759 - MSE: 0.1039 - precision: 0.8137 - recall: 0.7294 - val_loss: 1.1213 - val_accuracy: 0.5955 - val_MSE: 0.1816 - val_precision: 0.6217 - val_recall: 0.5569\n",
      "Epoch 31/80\n",
      "257/256 [==============================] - 59s 229ms/step - loss: 0.8455 - accuracy: 0.7779 - MSE: 0.1041 - precision: 0.8133 - recall: 0.7279 - val_loss: 1.1478 - val_accuracy: 0.6108 - val_MSE: 0.1801 - val_precision: 0.6388 - val_recall: 0.5729\n",
      "Epoch 32/80\n",
      "257/256 [==============================] - 67s 261ms/step - loss: 0.8373 - accuracy: 0.7795 - MSE: 0.1018 - precision: 0.8171 - recall: 0.7335 - val_loss: 1.1190 - val_accuracy: 0.6132 - val_MSE: 0.1799 - val_precision: 0.6361 - val_recall: 0.5736- accuracy: 0.7817 - MSE: 0.101 - ETA: 10s - loss: 0.8322 - accuracy: 0.7819 - MSE: 0.1010 - precision: 0.81 - ETA: 6s - loss: 0.8375 - accuracy: 0.7792 - MSE: 0.1017 - precision: 0.8174 - r - ETA: 4s - loss: 0.8374 - accuracy: 0.7799 - MSE: 0.1016 - precision: 0.8175 - recall: 0.7 - ETA: 3s - loss: 0.8371 - accuracy: 0.7798 - MSE: 0.1016 - precision: 0.8174 - recall: 0.7 - ETA: 2s - loss: 0.8370 - accuracy: 0.7795 - MSE: 0.1017 - precision: 0.8171 - r\n",
      "Epoch 33/80\n",
      "257/256 [==============================] - 68s 263ms/step - loss: 0.8404 - accuracy: 0.7756 - MSE: 0.1034 - precision: 0.8110 - recall: 0.7290 - val_loss: 1.0988 - val_accuracy: 0.6111 - val_MSE: 0.1769 - val_precision: 0.6352 - val_recall: 0.5653 0.8200 - accuracy: 0.778 - ETA: 46s - loss: 0.8299 - accuracy: 0.7668 - MSE: 0.1053 - precis - ETA: 44s - loss: 0.8377 - accuracy: 0.7 - ETA: 3s - loss: 0.8411 - accuracy: 0.7748 - MSE: 0.1037 - precision: 0.809\n",
      "Epoch 34/80\n",
      "257/256 [==============================] - 69s 269ms/step - loss: 0.8310 - accuracy: 0.7799 - MSE: 0.1018 - precision: 0.8176 - recall: 0.7346 - val_loss: 1.1151 - val_accuracy: 0.6174 - val_MSE: 0.1759 - val_precision: 0.6502 - val_recall: 0.5840ETA: 18 - ETA: 6s - loss: 0.8279 - accuracy: 0.7804 - MSE: 0.1015 - pre\n",
      "Epoch 35/80\n",
      "257/256 [==============================] - 84s 328ms/step - loss: 0.8417 - accuracy: 0.7842 - MSE: 0.1014 - precision: 0.8196 - recall: 0.7399 - val_loss: 1.1271 - val_accuracy: 0.6219 - val_MSE: 0.1781 - val_precision: 0.6419 - val_recall: 0.5875\n",
      "Epoch 36/80\n",
      "257/256 [==============================] - 77s 300ms/step - loss: 0.8369 - accuracy: 0.7817 - MSE: 0.1004 - precision: 0.8175 - recall: 0.7401 - val_loss: 1.1461 - val_accuracy: 0.6090 - val_MSE: 0.1814 - val_precision: 0.6312 - val_recall: 0.5813\n",
      "Epoch 37/80\n",
      "257/256 [==============================] - 80s 312ms/step - loss: 0.8332 - accuracy: 0.7822 - MSE: 0.1003 - precision: 0.8154 - recall: 0.7390 - val_loss: 1.1115 - val_accuracy: 0.6267 - val_MSE: 0.1765 - val_precision: 0.6471 - val_recall: 0.5889\n",
      "Epoch 38/80\n",
      "257/256 [==============================] - 78s 304ms/step - loss: 0.8237 - accuracy: 0.7836 - MSE: 0.0998 - precision: 0.8170 - recall: 0.7423 - val_loss: 1.0998 - val_accuracy: 0.6083 - val_MSE: 0.1785 - val_precision: 0.6305 - val_recall: 0.5722\n",
      "Epoch 39/80\n",
      "257/256 [==============================] - 78s 304ms/step - loss: 0.8181 - accuracy: 0.7862 - MSE: 0.0989 - precision: 0.8199 - recall: 0.7467 - val_loss: 1.1166 - val_accuracy: 0.6222 - val_MSE: 0.1780 - val_precision: 0.6457 - val_recall: 0.5955\n",
      "Epoch 40/80\n",
      "257/256 [==============================] - 78s 302ms/step - loss: 0.8107 - accuracy: 0.7876 - MSE: 0.0986 - precision: 0.8202 - recall: 0.7501 - val_loss: 1.0894 - val_accuracy: 0.6226 - val_MSE: 0.1747 - val_precision: 0.6455 - val_recall: 0.5868\n",
      "Epoch 41/80\n",
      "257/256 [==============================] - 78s 302ms/step - loss: 0.8064 - accuracy: 0.7929 - MSE: 0.0970 - precision: 0.8243 - recall: 0.7518 - val_loss: 1.0957 - val_accuracy: 0.6219 - val_MSE: 0.1748 - val_precision: 0.6520 - val_recall: 0.5823\n",
      "Epoch 42/80\n",
      "257/256 [==============================] - 78s 303ms/step - loss: 0.8135 - accuracy: 0.7841 - MSE: 0.0992 - precision: 0.8156 - recall: 0.7460 - val_loss: 1.0763 - val_accuracy: 0.6354 - val_MSE: 0.1727 - val_precision: 0.6558 - val_recall: 0.6007\n",
      "Epoch 43/80\n",
      "257/256 [==============================] - 78s 303ms/step - loss: 0.8039 - accuracy: 0.7909 - MSE: 0.0969 - precision: 0.8214 - recall: 0.7526 - val_loss: 1.0922 - val_accuracy: 0.6253 - val_MSE: 0.1773 - val_precision: 0.6484 - val_recall: 0.5840\n",
      "Epoch 44/80\n",
      "257/256 [==============================] - 78s 304ms/step - loss: 0.8079 - accuracy: 0.7892 - MSE: 0.0981 - precision: 0.8218 - recall: 0.7502 - val_loss: 1.1095 - val_accuracy: 0.6139 - val_MSE: 0.1812 - val_precision: 0.6326 - val_recall: 0.5816\n",
      "Epoch 45/80\n",
      "257/256 [==============================] - 80s 310ms/step - loss: 0.8067 - accuracy: 0.7931 - MSE: 0.0957 - precision: 0.8243 - recall: 0.7562 - val_loss: 1.1013 - val_accuracy: 0.6257 - val_MSE: 0.1770 - val_precision: 0.6453 - val_recall: 0.5875\n",
      "Epoch 46/80\n",
      "257/256 [==============================] - 79s 307ms/step - loss: 0.7932 - accuracy: 0.7901 - MSE: 0.0966 - precision: 0.8212 - recall: 0.7534 - val_loss: 1.1143 - val_accuracy: 0.6281 - val_MSE: 0.1781 - val_precision: 0.6436 - val_recall: 0.5976\n",
      "Epoch 47/80\n",
      "257/256 [==============================] - 82s 317ms/step - loss: 0.7973 - accuracy: 0.7982 - MSE: 0.0948 - precision: 0.8296 - recall: 0.7612 - val_loss: 1.0946 - val_accuracy: 0.6243 - val_MSE: 0.1779 - val_precision: 0.6439 - val_recall: 0.5951\n",
      "Epoch 48/80\n",
      "257/256 [==============================] - 79s 306ms/step - loss: 0.7920 - accuracy: 0.7989 - MSE: 0.0944 - precision: 0.8293 - recall: 0.7619 - val_loss: 1.1046 - val_accuracy: 0.6333 - val_MSE: 0.1743 - val_precision: 0.6557 - val_recall: 0.5972\n",
      "Epoch 49/80\n",
      "257/256 [==============================] - 79s 308ms/step - loss: 0.7927 - accuracy: 0.7958 - MSE: 0.0950 - precision: 0.8243 - recall: 0.7602 - val_loss: 1.1339 - val_accuracy: 0.6122 - val_MSE: 0.1854 - val_precision: 0.6268 - val_recall: 0.5896\n",
      "Epoch 50/80\n",
      "257/256 [==============================] - 79s 308ms/step - loss: 0.7900 - accuracy: 0.7969 - MSE: 0.0939 - precision: 0.8271 - recall: 0.7631 - val_loss: 1.0979 - val_accuracy: 0.6181 - val_MSE: 0.1794 - val_precision: 0.6331 - val_recall: 0.5903\n",
      "Epoch 51/80\n",
      "257/256 [==============================] - 77s 300ms/step - loss: 0.7809 - accuracy: 0.7978 - MSE: 0.0936 - precision: 0.8277 - recall: 0.7639 - val_loss: 1.0988 - val_accuracy: 0.6240 - val_MSE: 0.1765 - val_precision: 0.6510 - val_recall: 0.5920\n",
      "Epoch 52/80\n",
      "257/256 [==============================] - 70s 271ms/step - loss: 0.7833 - accuracy: 0.8002 - MSE: 0.0933 - precision: 0.8292 - recall: 0.7678 - val_loss: 1.1261 - val_accuracy: 0.6278 - val_MSE: 0.1781 - val_precision: 0.6486 - val_recall: 0.6000\n",
      "Epoch 53/80\n",
      "257/256 [==============================] - 52s 204ms/step - loss: 0.7863 - accuracy: 0.8008 - MSE: 0.0935 - precision: 0.8282 - recall: 0.7657 - val_loss: 1.0793 - val_accuracy: 0.6306 - val_MSE: 0.1752 - val_precision: 0.6513 - val_recall: 0.6024\n",
      "Epoch 54/80\n",
      "257/256 [==============================] - 59s 229ms/step - loss: 0.7827 - accuracy: 0.7996 - MSE: 0.0945 - precision: 0.8290 - recall: 0.7659 - val_loss: 1.0930 - val_accuracy: 0.6392 - val_MSE: 0.1737 - val_precision: 0.6564 - val_recall: 0.6076\n",
      "Epoch 55/80\n",
      "257/256 [==============================] - 74s 288ms/step - loss: 0.7816 - accuracy: 0.7990 - MSE: 0.0941 - precision: 0.8263 - recall: 0.7633 - val_loss: 1.0871 - val_accuracy: 0.6313 - val_MSE: 0.1782 - val_precision: 0.6443 - val_recall: 0.6038\n",
      "Epoch 56/80\n",
      "257/256 [==============================] - 69s 267ms/step - loss: 0.7778 - accuracy: 0.8022 - MSE: 0.0922 - precision: 0.8312 - recall: 0.7711 - val_loss: 1.0974 - val_accuracy: 0.6330 - val_MSE: 0.1776 - val_precision: 0.6529 - val_recall: 0.6073\n",
      "Epoch 57/80\n",
      "257/256 [==============================] - 47s 181ms/step - loss: 0.7754 - accuracy: 0.8051 - MSE: 0.0918 - precision: 0.8321 - recall: 0.7705 - val_loss: 1.1173 - val_accuracy: 0.6274 - val_MSE: 0.1787 - val_precision: 0.6446 - val_recall: 0.6052\n",
      "Epoch 58/80\n",
      "257/256 [==============================] - 46s 178ms/step - loss: 0.7809 - accuracy: 0.8015 - MSE: 0.0928 - precision: 0.8272 - recall: 0.7679 - val_loss: 1.1659 - val_accuracy: 0.6240 - val_MSE: 0.1830 - val_precision: 0.6407 - val_recall: 0.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/80\n",
      "257/256 [==============================] - 46s 177ms/step - loss: 0.7755 - accuracy: 0.8058 - MSE: 0.0913 - precision: 0.8336 - recall: 0.7740 - val_loss: 1.0933 - val_accuracy: 0.6406 - val_MSE: 0.1715 - val_precision: 0.6556 - val_recall: 0.6122\n",
      "Epoch 60/80\n",
      "257/256 [==============================] - 46s 178ms/step - loss: 0.7746 - accuracy: 0.8045 - MSE: 0.0907 - precision: 0.8323 - recall: 0.7744 - val_loss: 1.0946 - val_accuracy: 0.6271 - val_MSE: 0.1778 - val_precision: 0.6423 - val_recall: 0.6049\n",
      "Epoch 61/80\n",
      "257/256 [==============================] - 48s 187ms/step - loss: 0.7674 - accuracy: 0.8077 - MSE: 0.0915 - precision: 0.8350 - recall: 0.7771 - val_loss: 1.1249 - val_accuracy: 0.6226 - val_MSE: 0.1887 - val_precision: 0.6373 - val_recall: 0.6076cy: 0.8057 - MSE: 0.0922 \n",
      "Epoch 62/80\n",
      "257/256 [==============================] - 48s 187ms/step - loss: 0.7777 - accuracy: 0.8067 - MSE: 0.0910 - precision: 0.8312 - recall: 0.7735 - val_loss: 1.0999 - val_accuracy: 0.6319 - val_MSE: 0.1768 - val_precision: 0.6473 - val_recall: 0.6042\n",
      "Epoch 63/80\n",
      "257/256 [==============================] - 46s 178ms/step - loss: 0.7771 - accuracy: 0.8027 - MSE: 0.0926 - precision: 0.8280 - recall: 0.7679 - val_loss: 1.0780 - val_accuracy: 0.6288 - val_MSE: 0.1767 - val_precision: 0.6442 - val_recall: 0.6042\n",
      "Epoch 64/80\n",
      "257/256 [==============================] - 47s 182ms/step - loss: 0.7802 - accuracy: 0.8029 - MSE: 0.0917 - precision: 0.8266 - recall: 0.7706 - val_loss: 1.1214 - val_accuracy: 0.6347 - val_MSE: 0.1754 - val_precision: 0.6486 - val_recall: 0.6083\n",
      "Epoch 65/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.7723 - accuracy: 0.8055 - MSE: 0.0903 - precision: 0.8310 - recall: 0.7743 - val_loss: 1.1246 - val_accuracy: 0.6215 - val_MSE: 0.1848 - val_precision: 0.6380 - val_recall: 0.6021\n",
      "Epoch 66/80\n",
      "257/256 [==============================] - 44s 172ms/step - loss: 0.7673 - accuracy: 0.8085 - MSE: 0.0895 - precision: 0.8339 - recall: 0.7764 - val_loss: 1.1190 - val_accuracy: 0.6271 - val_MSE: 0.1807 - val_precision: 0.6382 - val_recall: 0.6069\n",
      "Epoch 67/80\n",
      "257/256 [==============================] - 43s 169ms/step - loss: 0.7629 - accuracy: 0.8092 - MSE: 0.0903 - precision: 0.8357 - recall: 0.7766 - val_loss: 1.0950 - val_accuracy: 0.6253 - val_MSE: 0.1792 - val_precision: 0.6374 - val_recall: 0.6073\n",
      "Epoch 68/80\n",
      "257/256 [==============================] - 45s 177ms/step - loss: 0.7710 - accuracy: 0.8062 - MSE: 0.0912 - precision: 0.8318 - recall: 0.7740 - val_loss: 1.0665 - val_accuracy: 0.6330 - val_MSE: 0.1743 - val_precision: 0.6444 - val_recall: 0.61530912 - precision: 0.831\n",
      "Epoch 69/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.7665 - accuracy: 0.8090 - MSE: 0.0893 - precision: 0.8336 - recall: 0.7779 - val_loss: 1.0883 - val_accuracy: 0.6347 - val_MSE: 0.1764 - val_precision: 0.6517 - val_recall: 0.6101\n",
      "Epoch 70/80\n",
      "257/256 [==============================] - 45s 174ms/step - loss: 0.7693 - accuracy: 0.8065 - MSE: 0.0907 - precision: 0.8327 - recall: 0.7766 - val_loss: 1.1012 - val_accuracy: 0.6240 - val_MSE: 0.1815 - val_precision: 0.6342 - val_recall: 0.6080\n",
      "Epoch 71/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.7729 - accuracy: 0.8054 - MSE: 0.0901 - precision: 0.8335 - recall: 0.7759 - val_loss: 1.1005 - val_accuracy: 0.6330 - val_MSE: 0.1735 - val_precision: 0.6492 - val_recall: 0.6111\n",
      "Epoch 72/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.7741 - accuracy: 0.8064 - MSE: 0.0905 - precision: 0.8317 - recall: 0.7743 - val_loss: 1.1304 - val_accuracy: 0.6340 - val_MSE: 0.1755 - val_precision: 0.6490 - val_recall: 0.6170\n",
      "Epoch 73/80\n",
      "257/256 [==============================] - 45s 176ms/step - loss: 0.7717 - accuracy: 0.8077 - MSE: 0.0902 - precision: 0.8336 - recall: 0.7783 - val_loss: 1.0932 - val_accuracy: 0.6302 - val_MSE: 0.1771 - val_precision: 0.6468 - val_recall: 0.6104\n",
      "Epoch 74/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.7675 - accuracy: 0.8051 - MSE: 0.0907 - precision: 0.8295 - recall: 0.7750 - val_loss: 1.0666 - val_accuracy: 0.6385 - val_MSE: 0.1723 - val_precision: 0.6547 - val_recall: 0.6097\n",
      "Epoch 75/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7664 - accuracy: 0.8115 - MSE: 0.0888 - precision: 0.8365 - recall: 0.7823 - val_loss: 1.1158 - val_accuracy: 0.6326 - val_MSE: 0.1758 - val_precision: 0.6510 - val_recall: 0.6139\n",
      "Epoch 76/80\n",
      "257/256 [==============================] - 45s 173ms/step - loss: 0.7602 - accuracy: 0.8096 - MSE: 0.0893 - precision: 0.8342 - recall: 0.7800 - val_loss: 1.0958 - val_accuracy: 0.6365 - val_MSE: 0.1746 - val_precision: 0.6536 - val_recall: 0.6205\n",
      "Epoch 77/80\n",
      "257/256 [==============================] - 45s 174ms/step - loss: 0.7696 - accuracy: 0.8088 - MSE: 0.0892 - precision: 0.8336 - recall: 0.7785 - val_loss: 1.0756 - val_accuracy: 0.6212 - val_MSE: 0.1789 - val_precision: 0.6364 - val_recall: 0.6017\n",
      "Epoch 78/80\n",
      "257/256 [==============================] - 46s 180ms/step - loss: 0.7724 - accuracy: 0.8080 - MSE: 0.0898 - precision: 0.8346 - recall: 0.7799 - val_loss: 1.1089 - val_accuracy: 0.6247 - val_MSE: 0.1784 - val_precision: 0.6415 - val_recall: 0.6045\n",
      "Epoch 79/80\n",
      "257/256 [==============================] - 46s 181ms/step - loss: 0.7612 - accuracy: 0.8082 - MSE: 0.0886 - precision: 0.8340 - recall: 0.7803 - val_loss: 1.1419 - val_accuracy: 0.6288 - val_MSE: 0.1825 - val_precision: 0.6404 - val_recall: 0.6115\n",
      "Epoch 80/80\n",
      "257/256 [==============================] - 45s 175ms/step - loss: 0.7600 - accuracy: 0.8104 - MSE: 0.0881 - precision: 0.8352 - recall: 0.7814 - val_loss: 1.1407 - val_accuracy: 0.6170 - val_MSE: 0.1851 - val_precision: 0.6294 - val_recall: 0.6021\n"
     ]
    }
   ],
   "source": [
    "scaler = None\n",
    "if use_scaler:\n",
    "    scaler = StandardScalerFitter(train_ds).fit_scaler(test = test, detrend = detrend)\n",
    "aug = None\n",
    "if use_noise_augmentor:\n",
    "    aug = NoiseAugmentor(train_ds, use_scaler, scaler)\n",
    "    \n",
    "    \n",
    "\n",
    "gen_args = {\n",
    "    'batch_size' : batch_size,\n",
    "    'test' : test,\n",
    "    'detrend' : detrend,\n",
    "    'use_scaler' : use_scaler,\n",
    "    'scaler' : scaler,\n",
    "    'use_noise_augmentor' : use_noise_augmentor,\n",
    "    'augmentor' : aug,\n",
    "    'num_classes' : num_classes,\n",
    "    'use_highpass' : use_highpass,\n",
    "    'highpass_freq' : highpass_freq\n",
    "}\n",
    "\n",
    "\n",
    "train_gen = data_gen.data_generator(train_ds, **gen_args)\n",
    "val_gen = data_gen.data_generator(val_ds, **gen_args)\n",
    "test_gen = data_gen.data_generator(test_ds, **gen_args)\n",
    "\n",
    "\n",
    "\n",
    "args = {'steps_per_epoch' : helper.get_steps_per_epoch(train_ds, batch_size, test),\n",
    "        'epochs' : epochs,\n",
    "        'validation_data' : val_gen,\n",
    "        'validation_steps' : helper.get_steps_per_epoch(val_ds, batch_size, test),\n",
    "        'verbose' : 1,\n",
    "        'use_multiprocessing' : False, \n",
    "        'workers' : 1,\n",
    "        'callbacks' : [callbacks]\n",
    "}\n",
    "\n",
    "model_fit = model.fit(train_gen, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-caff4dd8bda0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_training_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_callback' is not defined"
     ]
    }
   ],
   "source": [
    "full_logs = custom_callback.full_training_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.get_n_points_with_highest_training_loss(train_ds, 100, full_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_points_with_highest_training_loss(full_logs, train_ds, n):\n",
    "    train_ds_dict = {}\n",
    "    for path, label in train_ds:\n",
    "        train_ds_dict[path] = {'label' : label,\n",
    "                               'loss': 0,\n",
    "                               'average_loss' : 0,\n",
    "                               'occurances' : 0}\n",
    "    counter = 0\n",
    "    for batch in full_logs:\n",
    "        loss = batch['loss']\n",
    "        for path_class in batch['batch_samples']:\n",
    "            train_ds_dict[path_class[0]]['loss'] += loss\n",
    "            train_ds_dict[path_class[0]]['occurances'] += 1\n",
    "    \n",
    "    train_ds_list = []\n",
    "    for sample in np.array(train_ds[:,0]):\n",
    "        if train_ds_dict[sample]['occurances'] == 0:\n",
    "            continue\n",
    "        train_ds_dict[sample]['average_loss'] = train_ds_dict[sample]['loss'] / train_ds_dict[sample]['occurances']\n",
    "        train_ds_list.append((sample, train_ds_dict[sample]['label'],train_ds_dict[sample]['average_loss']))\n",
    "    \n",
    "    sorted_train_ds_list = sorted(train_ds_list, key=lambda x: x[2], reverse = True)\n",
    "        \n",
    "    \n",
    "    return sorted_train_ds_list[0:n]\n",
    "        \n",
    "#get_n_points_with_highest_loss(full_logs, train_ds, 100)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator=test_gen, steps=helper.get_steps_per_epoch(test_ds, batch_size, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_true_categorical.argmax(axis=1), predictions[0:1234].argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Documents\\Thesis_ssd\\MasterThesis-2.0\\Classes\\DataProcessing\\BaselineHelperFunctions.py:45: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "[[208 126  56]\n",
      " [ 56 365   8]\n",
      " [120  57 238]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_confusion_matrix(model, test_gen, test_ds, batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_generator(val_gen, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_confusion_matrix(test_ds, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
